---
layout:     post
title:      视频数据编解码技术
subtitle:   
date:       2010-12-29
author:     spin6lock
header-img: img/post-bg-universe.jpg
catalog: true
tags:
    - python
---
我真的很难专心持续做一件事情呢，最近因为课程需要写了篇文章应付，博诸君一笑

** 视频编码与文件格式的常见误区 **

常见的视频编码

MPEG2

MPEG-2 是 MPEG 工作组于 1994 年发布的视频和音频压缩国际标准。MPEG-2 通常用来为广播信号提供视频和音频编码，包括卫星电视、有线电视等。MPEG-2 经过少量修改后，也成为 DVD 产品的核心技术。MPEG-2 的系统描述部分（第 1 部分）定义了传输流，它用来一套在非可靠介质上传输数字视频信号和音频信号的机制，主要用在广播电视领域。MPEG-2 的第二部分即视频部分和 MPEG-1 类似，但是它提供对隔行扫描视频显示模式的支持（隔行扫描广泛应用在广播电视领域）。MPEG-2 视频并没有对低位速率（小于 1Mbps）进行优化，在 3Mbit/s 及以上位速率情况下，MPEG-2 明显优于 MPEG-1。MPEG-2 向后兼容，也即是说，所有符合标准的 MPEG-2 解码器也能够正常播放 MPEG-1 视频流。MPEG-2 技术也应用在了 HDTV 传输系统中。MPEG-2 的第三部分定义了音频压缩标准。该部分改进了 MPEG-1 的音频压缩，支持两通道以上的音频。MPEG-2 音频压缩部分也保持了向后兼容的特点。MPEG-2 的第七部分定义了不能向后兼容的音频压缩。该部分提供了更强的音频功能。通常我们所说的 MPEG-2AAC 指的就是这一部分。

MPEG4

MPEG-4 是一套用于音频、视频信息的压缩编码标准，由国际标准化组织（ISO）和国际电工委员会（IEC）下属的动态图像专家组（Moving Picture Experts Group，即 MPEG）制定，第一版在 1998 年 10 月通过，第二版在 1999 年 12 月通过。MPEG-4 格式的主要用途在于网上流、光盘、语音传送（视频电话），以及电视广播。MPEG-4 包含了 MPEG-1 及 MPEG-2 的绝大部份功能及其他格式的长处，并加入及扩充对虚拟现实模型语言（VRML ， Virtual Reality Modeling Language）的支持，面向对象的合成文件（包括音效，视频及 VRML 对象），以及数字版权管理（DRM）及其他交互功能。MPEG-4 大部份功能都留待开发者决定采用是否。这意味着整个格式的功能不一定被某个程序所完全函括。因此，这个格式有所谓 profiles 及层次（levels），定义了 MPEG-4 用于某些特定应用的某些功能的集合。

H.264

H.264，或称 MPEG-4 第十部分，是由 ITU-T 视频编码专家组（VCEG）和 ISO／IEC 动态图像专家组（MPEG）联合组成的联合视频组（JVT，Joint Video Team）提出的高度压缩数字视频编解码器标准。

MPEG7 

MPEG-7 标准被称为多媒体内容描述接口，为各类多媒体信息提供一种标准化的描述，这种描述将与内容本身有关，允许快速和有效的查询用户感兴趣的资料。它将扩展现有内容识别专用解决方案的有限的能力，特别是它还包括了更多的数据类型。换而言之，MPEG-7 规定一个用于描述各种不同类型多媒体信息的描述符的标准集合。该标准于 1998 年 10 月提出。 

** 视频解码的常见过程 **

视频解码的 4 个过程，通常包括获取文件、分离音视频流、解码、输出。

　　获取文件

　　　　视频流的来源可以是文件，也可以是 UDP 等数据流，主要是将视频流放入内存缓冲区中。

　　分离音视频流

　　　　正如前述，视频文件只是一个容器。视频数据与音频数据按照一定的标准组合在一起。为了下一步的解码，首先要把视频和音频分离开。

　　解码工作

　　　　分离开的音频和视频，由各自的 codec 负责进行解码，得到原始数据流。

　　输出

　　　　将得到的原始数据流在窗口里进行渲染，使之变成可以看到的图像。

** 视频编码的核心过程 **

下面以现时的 MPEG1 编码为例，试讲述视频编码的核心过程。通过摄影机、摄像头等得到的图像，首先会进行模数转换，变成数字码流。但是，在时间尺度上和空间范围上，均有大量的冗余信息，得到的比特流会占用大量的空间，不利于储存和播放。因此，就需要对原始视频流进行编码压缩。常见的方法是，对原始视频流进行色彩空间转换。由于人眼对于亮度的敏感大大优于对色度的敏感，转化为 YCbCr 色彩空间能够缩小体积而视频质量仍保持在较高质素（同时，这也去除了色彩方面的冗余）。接着进行 DCT 离散余弦变换，由于离散视频变换具有很强的能量集中特性，大多数自然信号（包括声音和图像）都会集中在离散余弦变换后的低频部分。（这意味着系数矩阵的大多数元素均为 0）通过量化，就可以进行熵编码。上一步得到的数据往往具有较高的冗余量，对其进行熵编码（如常见的霍夫曼编码）就会有较好的压缩效果。

　　对于视频来说，往往会进行运动补偿，使用已经编码的帧对当前帧进行预测。最简单的运动编码可以是将当前帧减去参考帧，对剩余部分（只剩下较少能量的残差）进行较低码流的编码。比较常用的是分块运动补偿，通过对宏块的平移预测当前帧。其中，涉及到探测并计算最优平移向量。当然，还有通过向前向后预测来优化的（向前向后是指同时使用前后两个参考帧进行预测）。

参见：

　　维基百科
